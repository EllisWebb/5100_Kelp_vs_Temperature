


import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt





bed_vars= [
    'Aiston_Preserve','Biz_Point','Cherry_Point_Gulf_Rd','Clallam_Bay','Coffin_Rocks',
    'Ebeys_Landing','Freshwater_Bay_1','Freshwater_Bay_2','Hat_Island','Hoypus_Point',
    'Lowell','Lummi_SW','North_Beach_East','Polnell_Point','Possession_Point',
    'Shannon_Point_East','Shannon_Point_West'
]

path = "https://raw.githubusercontent.com/sgolden3/Data-5100-Kelp/refs/heads/main/Data/cleaned_data/"


def dataimport(bed_vars, path):


    for var in bed_vars:
        globals()[var] = pd.read_csv(path + var + ".csv")

        


dataimport(bed_vars, path) 


Ebeys_Landing.info()











def prepare_temp_max_extent(df):
  
    df["Temp_Final"] = np.where(
        ~df["Temp"].isna(),
        df["Temp"],
        np.where(
            (~df["Ave Temp Shore Edge"].isna()) &
            (~df["Ave Temp Water Edge"].isna()),
            (df["Ave Temp Shore Edge"] + df["Ave Temp Water Edge"]) / 2,
            (
                ((df["Temp1 Shore Edge"] + df["Temp2 Shore Edge"]) / 2) +
                ((df["Temp1 Water Edge"] + df["Temp2 Water Edge"]) / 2)
            ) / 2
        )
    )

    
    df["Survey Date"] = pd.to_datetime(df["Survey Date"])


    
    df_max = (
        df[df["NWSC Max Ext"] == 1]
        .sort_values(["Site Code", "Survey Year", "Acres"],
                     ascending=[True, True, False])
        .drop_duplicates(subset=["Site Code", "Survey Year"], keep="first")
        .copy()
    )


    
    df_max["PctAcreChange"] = (
        df_max.groupby("Site Code")["Acres"]
              .pct_change()
              * 100
    )

    

    df_max["Temp_t"] = df_max["Temp_Final"]

    return df_max








def add_offset_temperatures(df_max):
   

    def get_temp_for_date_and_site(target_date, site_code_to_match, df_filtered_for_temp):
        match = df_filtered_for_temp[
            (df_filtered_for_temp['Site Code'] == site_code_to_match) &
            (df_filtered_for_temp['Survey Date'].dt.year == target_date.year)
        ]
        if not match.empty:
            return match['Temp_Final'].iloc[0]
        return pd.NA

    
    def get_historical_temperatures(row, df_search):
        current_date = row['Survey Date']
        current_site_code = row['Site Code']

        if pd.isna(current_date):
            return pd.Series({
                "Temp_t_minus1": pd.NA,
                "Temp_t_minus2": pd.NA,
                "Temp_t_minus3": pd.NA,
                "Temp_t_minus4": pd.NA,
            })

        one_year_ago    = current_date - pd.DateOffset(years=1)
        two_years_ago   = current_date - pd.DateOffset(years=2)
        three_years_ago = current_date - pd.DateOffset(years=3)
        four_years_ago  = current_date - pd.DateOffset(years=4)

        temp_1 = get_temp_for_date_and_site(one_year_ago,    current_site_code, df_search)
        temp_2 = get_temp_for_date_and_site(two_years_ago,   current_site_code, df_search)
        temp_3 = get_temp_for_date_and_site(three_years_ago, current_site_code, df_search)
        temp_4 = get_temp_for_date_and_site(four_years_ago,  current_site_code, df_search)

        return pd.Series(
            {
                "Temp_t_minus1": temp_1,
                "Temp_t_minus2": temp_2,
                "Temp_t_minus3": temp_3,
                "Temp_t_minus4": temp_4,
            }
        )


    
    df_max[
        ["Temp_t_minus1",
         "Temp_t_minus2",
         "Temp_t_minus3",
         "Temp_t_minus4"]
    ] = df_max.apply(get_historical_temperatures, axis=1, args=(df_max,))


    
    temp_cols = [
        "Temp_t",
        "Temp_t_minus1",
        "Temp_t_minus2",
        "Temp_t_minus3",
        "Temp_t_minus4"
    ]
    

    monthly_avgs = (
        df_max.groupby(["Site Code", "Survey Month"])["Temp_Final"]
              .mean()
              .rename("MonthlyTempMean")
    )
    

    df_max = df_max.merge(monthly_avgs, on=["Site Code", "Survey Month"], how="left")
    

    for col in temp_cols:
        df_max[col] = df_max[col].fillna(df_max["MonthlyTempMean"])
        

    return df_max





def corr_pairplot_and_heatmap(df_max, title=None):

 
    predictor_variables = [
        "Temp_t",
        "Temp_t_minus1",
        "Temp_t_minus2",
        "Temp_t_minus3",
        "Temp_t_minus4"
    ]


    numerical_predictors = (
        df_max[predictor_variables]
        .select_dtypes(include="number")
        .columns
        .to_list()
    )


    corr_matrix = df_max[numerical_predictors + ["Acres", "PctAcreChange"]].corr()


    selected_cols = [
        "Bed Name", "Site Code", "Survey Day", "Survey Month", "Survey Year",
        "Acres",
        "Temp_t",
        "Temp_t_minus1",
        "Temp_t_minus2",
        "Temp_t_minus3",
        "Temp_t_minus4",
        "PctAcreChange",
    ]

    df_selected = df_max[selected_cols]

    g = sns.pairplot(
        data=df_selected,
        vars=numerical_predictors + ["Acres", "PctAcreChange"],
        kind="reg",
        plot_kws={"scatter_kws": {"alpha": 0.5, "color": "k", "s": 7}},
    )

    cmap = plt.get_cmap("gist_earth")


    norm = plt.Normalize(vmin=-1, vmax=1)

    for i, row_var in enumerate(corr_matrix.columns):
        for j, col_var in enumerate(corr_matrix.columns):
            ax = g.axes[i, j]
            if ax is not None:
                r = corr_matrix.loc[row_var, col_var]
                color = cmap(norm(r))
                ax.set_facecolor(color)

    for i, row_var in enumerate(corr_matrix.columns):
        for j, col_var in enumerate(corr_matrix.columns):

            ax = g.axes[i, j]
            if ax is not None:

                r = corr_matrix.loc[row_var, col_var]
                txt = f"{r:.2f}"

                ax.text(
                    0.05, 0.95, txt,
                    transform=ax.transAxes,
                    fontsize=10,
                    ha="left", va="top",
                    color="white", fontweight="bold",
                    bbox=dict(boxstyle="round,pad=0.2",
                              facecolor="black", alpha=0.3)
                )

    for ax in g.axes.flat:
        ax.set_xlabel(ax.get_xlabel(), fontsize=14, rotation=30, ha='right')
        ax.set_ylabel(ax.get_ylabel(), fontsize=14)
        plt.setp(ax.get_xticklabels(), rotation=30, ha='right')

    plt.suptitle("All Beds Pairplot & Correlation Heatmap", y=1.02, fontsize=20, fontweight='bold')

    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    g.fig.colorbar(sm, ax=g.axes, shrink=0.6, label="Correlation")

    plt.show()

    bed = df_max["Bed Name"].iloc[0]

    df_selected.to_csv(
        f"/Users/carterwebb/Desktop/kelps/data/cleaned_data/corr_dfs/{bed}_corrDF.csv",
        index=False
    )

    return df_selected





def max_corr_pipeline(df, title=None):
   
    df_max = prepare_temp_max_extent(df)
    df_max = add_offset_temperatures(df_max)

    df_selected = corr_pairplot_and_heatmap(df_max, title=title)
    return df_selected


    'Aiston_Preserve','Biz_Point','Cherry_Point_Gulf_Rd','Clallam_Bay','Coffin_Rocks',
    'Ebeys_Landing','Freshwater_Bay_1','Freshwater_Bay_2','Hat_Island','Hoypus_Point',
    'Lowell','Lummi_SW','North_Beach_East','Polnell_Point','Possession_Point',
    'Shannon_Point_East','Shannon_Point_West'


max_corr_pipeline(Polnell_Point)


max_corr_pipeline(Lumi_SW)


allbed = pd.read_csv("https://raw.githubusercontent.com/sgolden3/Data-5100-Kelp/refs/heads/main/Data/cleaned_data/AllBeds_Clean.csv")

allbed[["Temp1 Shore Edge","Temp2 Shore Edge","Temp1 Water Edge","Temp2 Water Edge"]] = \
allbed[["Temp1 Shore Edge","Temp2 Shore Edge","Temp1 Water Edge","Temp2 Water Edge"]].apply(pd.to_numeric, errors="coerce")


allbed = allbed.sort_values(["Site Code", "Survey Year"])


allbed["PctAcreChange"] = (
    allbed.groupby("Site Code")["Acres"].pct_change() * 100
)


allbed.info()


allbed = max_corr_pipeline(allbed)


allbed


 allbed.to_csv(
        f"/Users/carterwebb/Desktop/kelps/data/cleaned_data/corr_dfs/allbed_corrDF.csv",
        index=False
    )



